{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting git+https://github.com/huggingface/transformers/\n",
      "  Cloning https://github.com/huggingface/transformers/ to /private/var/folders/72/q4wkc759595dyy37dl7blq3r0000gn/T/pip-req-build-c68iunyx\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting datasets\n",
      "  Downloading datasets-1.6.2-py3-none-any.whl (221 kB)\n",
      "\u001b[K     |████████████████████████████████| 221 kB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.17\n",
      "  Downloading numpy-1.20.3-cp37-cp37m-macosx_10_9_x86_64.whl (16.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 16.0 MB 8.0 MB/s eta 0:00:01    |███████▎                        | 3.6 MB 3.7 MB/s eta 0:00:04\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /Users/weugene/anaconda3/lib/python3.7/site-packages (from transformers==4.7.0.dev0) (0.6)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
      "\u001b[K     |████████████████████████████████| 895 kB 6.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2021.4.4-cp37-cp37m-macosx_10_9_x86_64.whl (285 kB)\n",
      "\u001b[K     |████████████████████████████████| 285 kB 4.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /Users/weugene/anaconda3/lib/python3.7/site-packages (from transformers==4.7.0.dev0) (18.0)\n",
      "Requirement already satisfied: requests in /Users/weugene/anaconda3/lib/python3.7/site-packages (from transformers==4.7.0.dev0) (2.21.0)\n",
      "Requirement already satisfied: filelock in /Users/weugene/anaconda3/lib/python3.7/site-packages (from transformers==4.7.0.dev0) (3.0.10)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp37-cp37m-macosx_10_11_x86_64.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 5.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting huggingface-hub==0.0.8\n",
      "  Downloading huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/weugene/anaconda3/lib/python3.7/site-packages (from transformers==4.7.0.dev0) (4.28.1)\n",
      "Requirement already satisfied: pandas in /Users/weugene/anaconda3/lib/python3.7/site-packages (from datasets) (0.23.4)\n",
      "Collecting dill\n",
      "  Downloading dill-0.3.3-py2.py3-none-any.whl (81 kB)\n",
      "\u001b[K     |████████████████████████████████| 81 kB 6.8 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting fsspec\n",
      "  Downloading fsspec-2021.5.0-py3-none-any.whl (111 kB)\n",
      "\u001b[K     |████████████████████████████████| 111 kB 8.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting multiprocess\n",
      "  Downloading multiprocess-0.70.11.1-py37-none-any.whl (108 kB)\n",
      "\u001b[K     |████████████████████████████████| 108 kB 9.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting xxhash\n",
      "  Downloading xxhash-2.0.2-cp37-cp37m-macosx_10_9_x86_64.whl (31 kB)\n",
      "Collecting pyarrow>=1.0.0<4.0.0\n",
      "  Downloading pyarrow-4.0.0-cp37-cp37m-macosx_10_13_x86_64.whl (15.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.7 MB 8.9 MB/s eta 0:00:01     |███████████████████████         | 11.2 MB 8.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: click in /Users/weugene/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers==4.7.0.dev0) (7.0)\n",
      "Requirement already satisfied: six in /Users/weugene/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers==4.7.0.dev0) (1.12.0)\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "\u001b[K     |████████████████████████████████| 303 kB 7.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /Users/weugene/anaconda3/lib/python3.7/site-packages (from packaging->transformers==4.7.0.dev0) (2.3.0)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Users/weugene/anaconda3/lib/python3.7/site-packages (from requests->transformers==4.7.0.dev0) (1.24.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/weugene/anaconda3/lib/python3.7/site-packages (from requests->transformers==4.7.0.dev0) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/weugene/anaconda3/lib/python3.7/site-packages (from requests->transformers==4.7.0.dev0) (2020.12.5)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/weugene/anaconda3/lib/python3.7/site-packages (from requests->transformers==4.7.0.dev0) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /Users/weugene/anaconda3/lib/python3.7/site-packages (from pandas->datasets) (2.7.5)\n",
      "Requirement already satisfied: pytz>=2011k in /Users/weugene/anaconda3/lib/python3.7/site-packages (from pandas->datasets) (2018.7)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.7.0.dev0-py3-none-any.whl size=2309224 sha256=423b52abcc8035280c3148521de0f5b52076de030174eb356022e619dffa4283\n",
      "  Stored in directory: /private/var/folders/72/q4wkc759595dyy37dl7blq3r0000gn/T/pip-ephem-wheel-cache-3zft6hqd/wheels/fb/1b/91/0fcf504c386d427d65bbaf663eadf8e18cbf9795394ed7050d\n",
      "Successfully built transformers\n",
      "Installing collected packages: numpy, huggingface-hub, dill, fsspec, multiprocess, xxhash, pyarrow, datasets, joblib, regex, sacremoses, tokenizers, transformers\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.15.4\n",
      "    Uninstalling numpy-1.15.4:\n",
      "      Successfully uninstalled numpy-1.15.4\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "tensorflow 1.13.1 requires tensorboard<1.14.0,>=1.13.0, but you'll have tensorboard 1.14.0 which is incompatible.\n",
      "tensorflow 1.13.1 requires tensorflow-estimator<1.14.0rc0,>=1.13.0, but you'll have tensorflow-estimator 1.14.0 which is incompatible.\u001b[0m\n",
      "Successfully installed datasets-1.6.2 dill-0.3.3 fsspec-2021.5.0 huggingface-hub-0.0.8 joblib-1.0.1 multiprocess-0.70.11.1 numpy-1.20.3 pyarrow-4.0.0 regex-2021.4.4 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.7.0.dev0 xxhash-2.0.2\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/Users/weugene/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "I0525 19:39:22.618912 4653948416 filelock.py:274] Lock 140711452858352 acquired on /Users/weugene/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "768c8fde242d409f909cf1eabffd7486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=570, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0525 19:39:23.288048 4653948416 filelock.py:318] Lock 140711452858352 released on /Users/weugene/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0525 19:39:23.849848 4653948416 filelock.py:274] Lock 140711536803344 acquired on /Users/weugene/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a65191d762c40949ee7d45e2fd97b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=213450, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0525 19:39:24.613189 4653948416 filelock.py:318] Lock 140711536803344 released on /Users/weugene/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0525 19:39:25.201095 4653948416 filelock.py:274] Lock 140711535716056 acquired on /Users/weugene/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06a834484e5447de82a445255ffb91fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=435797, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0525 19:39:26.069475 4653948416 filelock.py:318] Lock 140711535716056 released on /Users/weugene/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0525 19:39:27.707782 4653948416 filelock.py:274] Lock 140711535716056 acquired on /Users/weugene/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53ba55a5513b4e2ca0780002ac0f1f15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=29, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0525 19:39:28.267647 4653948416 filelock.py:318] Lock 140711535716056 released on /Users/weugene/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nAutoModelForMaskedLM requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0aad81cb1ba4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"bert-base-cased\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_fast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForMaskedLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/transformers/utils/dummy_pt_objects.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mrequires_backends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"torch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__name__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBACKENDS_MAPPING\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBACKENDS_MAPPING\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: \nAutoModelForMaskedLM requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets git+https://github.com/huggingface/transformers/\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "model = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model, use_fast=True)\n",
    "model = AutoModelForMaskedLM.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Experts say Covid-19 vaccinations in the US are going extremely well -- but not enough people are protected yet and the country may be at the start of another surge. \n",
    "The US reported a record over the weekend with more than 4 million Covid-19 vaccine doses administered in 24 hours, according to the Centers for Disease Control and Prevention. \n",
    "And the country now averages more than 3 million doses daily, according to CDC data. \n",
    "But only about 18.5% of Americans are fully vaccinated, CDC data shows, and Covid-19 cases in the country have recently seen concerning increases. \\\n",
    "\"I do think we still have a few more rough weeks ahead,\" Dr. Celine Gounder, an infectious diseases specialist and epidemiologist, told CNN on Sunday. \"What we know from the past year of the pandemic is that we tend to trend about three to four weeks behind Europe in terms of our pandemic patterns.\"\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading https://nlp.h-its.org/bpemb/en/en.wiki.bpe.vs10000.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400869/400869 [00:08<00:00, 50006.64B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading https://nlp.h-its.org/bpemb/en/en.wiki.bpe.vs10000.d100.w2v.bin.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3784656/3784656 [01:05<00:00, 58186.14B/s]\n",
      "/Users/weugene/anaconda3/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "I0525 19:52:44.900175 4653948416 keyedvectors.py:1891] loading projection weights from /Users/weugene/.cache/bpemb/en/en.wiki.bpe.vs10000.d100.w2v.bin\n",
      "I0525 19:52:45.091653 4653948416 utils.py:448] KeyedVectors lifecycle event {'msg': 'loaded (10000, 100) matrix of type float32 from /Users/weugene/.cache/bpemb/en/en.wiki.bpe.vs10000.d100.w2v.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2021-05-25T19:52:44.983530', 'gensim': '4.0.1', 'python': '3.7.1 (default, Dec 14 2018, 13:28:58) \\n[Clang 4.0.1 (tags/RELEASE_401/final)]', 'platform': 'Darwin-20.3.0-x86_64-i386-64bit', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "#!pip install bpemb\n",
    "from bpemb import BPEmb\n",
    "bpemb_en = BPEmb(lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
